#!/usr/bin/env python3
"""
Pixabay Music Downloader Tool
Táº£i nháº¡c MP3 tá»« Pixabay vá»›i kháº£ nÄƒng chá»n range
"""

import requests
from bs4 import BeautifulSoup
import re
import os
import urllib.parse
from urllib.parse import urljoin
import time
import json
from typing import List, Dict, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from threading import Lock

class PixabayMusicDownloader:
    def __init__(self):
        self.session = requests.Session()
        # Headers máº¡nh hÆ¡n Ä‘á»ƒ giáº£ láº­p browser tháº­t
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9,vi;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Cache-Control': 'max-age=0'
        })
        self.music_list = []
        # Threading locks for thread-safe operations
        self.print_lock = Lock()
        self.progress_lock = Lock()
        
    def parse_pixabay_page(self, url: str) -> List[Dict]:
        """
        Parse trang Pixabay Ä‘á»ƒ láº¥y danh sÃ¡ch nháº¡c
        """
        print(f"ğŸ” Äang táº£i trang: {url}")
        
        try:
            # Thá»­ vá»›i delay vÃ  timeout Ä‘á»ƒ trÃ¡nh bá»‹ block
            time.sleep(2)
            response = self.session.get(url, timeout=30, allow_redirects=True)
            
            print(f"ğŸ“Š Status code: {response.status_code}")
            print(f"ğŸ“Š Content length: {len(response.content):,} bytes")
            
            if response.status_code == 403:
                print("âš ï¸  403 Forbidden - Thá»­ phÆ°Æ¡ng phÃ¡p khÃ¡c...")
                return self._try_alternative_methods(url)
            
            response.raise_for_status()
            
            music_items = self._parse_response_content(response.content, url)
            self.music_list = music_items
            return music_items
            
        except Exception as e:
            print(f"âŒ Lá»—i khi táº£i trang: {e}")
            print("ğŸ’¡ Thá»­ phÆ°Æ¡ng phÃ¡p thay tháº¿...")
            return self._try_alternative_methods(url)
    
    def _parse_single_page(self, page_url: str, page_num: int) -> Dict:
        """
        Parse má»™t trang Ä‘Æ¡n láº» - dÃ¹ng cho threading
        Returns: Dict vá»›i thÃ´ng tin káº¿t quáº£ parse
        """
        result = {
            'page_num': page_num,
            'success': False,
            'items': [],
            'error': None,
            'url': page_url
        }
        
        try:
            with self.print_lock:
                print(f"ğŸ“„ [{threading.current_thread().name}] Äang crawl trang {page_num}: {page_url}")
            
            # Parse trang hiá»‡n táº¡i
            page_items = self.parse_pixabay_page(page_url)
            
            if page_items:
                # ThÃªm page number vÃ o tá»«ng item
                for item in page_items:
                    item['page'] = page_num
                
                result['items'] = page_items
                result['success'] = True
                
                with self.print_lock:
                    print(f"âœ… [{threading.current_thread().name}] Trang {page_num}: ThÃªm {len(page_items)} tracks")
            else:
                result['error'] = "KhÃ´ng tÃ¬m tháº¥y tracks"
                with self.print_lock:
                    print(f"âŒ [{threading.current_thread().name}] Trang {page_num}: KhÃ´ng tÃ¬m tháº¥y tracks")
                    
        except Exception as e:
            result['error'] = str(e)
            with self.print_lock:
                print(f"âŒ [{threading.current_thread().name}] Lá»—i khi crawl trang {page_num}: {e}")
        
        return result

    def parse_multiple_pages(self, base_url: str, start_page: int = 1, end_page: int = 3, max_workers: int = 3) -> List[Dict]:
        """
        Parse nhiá»u trang Pixabay vá»›i pagination tá»« start_page Ä‘áº¿n end_page sá»­ dá»¥ng multi-threading
        max_workers: Sá»‘ thread tá»‘i Ä‘a cho parsing (máº·c Ä‘á»‹nh 3 Ä‘á»ƒ khÃ´ng lÃ m quÃ¡ táº£i server)
        """
        all_music_items = []
        total_pages = end_page - start_page + 1
        
        print(f"ğŸ“š Báº¯t Ä‘áº§u crawl tá»« trang {start_page} Ä‘áº¿n trang {end_page} ({total_pages} trang)...")
        print(f"ğŸ§µ Sá»­ dá»¥ng {max_workers} threads song song cho parsing")
        print("=" * 70)
        
        # Chuáº©n bá»‹ danh sÃ¡ch parse jobs
        parse_jobs = []
        for page_num in range(start_page, end_page + 1):
            # Táº¡o URL cho tá»«ng trang
            if page_num == 1 and 'pagi=' not in base_url:
                page_url = base_url
            else:
                # ThÃªm parameter pagi cho trang tiáº¿p theo
                separator = '&' if '?' in base_url else '?'
                if 'pagi=' in base_url:
                    # Replace existing pagi parameter
                    page_url = re.sub(r'pagi=\d+', f'pagi={page_num}', base_url)
                else:
                    page_url = f"{base_url}{separator}pagi={page_num}"
            
            parse_jobs.append((page_url, page_num))
        
        print(f"ğŸ“‹ ÄÃ£ chuáº©n bá»‹ {len(parse_jobs)} jobs parsing...")
        
        # Khá»Ÿi táº¡o counters
        successful_pages = 0
        failed_pages = 0
        completed_pages = 0
        
        # Sá»­ dá»¥ng ThreadPoolExecutor Ä‘á»ƒ parse song song
        with ThreadPoolExecutor(max_workers=max_workers, thread_name_prefix="Parser") as executor:
            # Submit táº¥t cáº£ jobs
            future_to_job = {
                executor.submit(self._parse_single_page, page_url, page_num): (page_url, page_num) 
                for page_url, page_num in parse_jobs
            }
            
            print(f"ğŸ¯ ÄÃ£ submit {len(future_to_job)} parse tasks...")
            print("â³ Äang crawl... (cÃ³ thá»ƒ máº¥t vÃ i phÃºt)")
            print("-" * 70)
            
            # Thu tháº­p káº¿t quáº£ theo thá»© tá»± hoÃ n thÃ nh
            page_results = {}
            
            for future in as_completed(future_to_job):
                page_url, page_num = future_to_job[future]
                completed_pages += 1
                
                try:
                    result = future.result()
                    page_results[page_num] = result
                    
                    with self.progress_lock:
                        if result['success']:
                            successful_pages += 1
                        else:
                            failed_pages += 1
                        
                        # Hiá»ƒn thá»‹ tiáº¿n Ä‘á»™
                        progress = (completed_pages / len(parse_jobs)) * 100
                        print(f"\nğŸ“Š Tiáº¿n Ä‘á»™ parsing: {completed_pages}/{len(parse_jobs)} ({progress:.1f}%)")
                        print(f"âœ… ThÃ nh cÃ´ng: {successful_pages} | âŒ Tháº¥t báº¡i: {failed_pages}")
                        
                except Exception as e:
                    with self.print_lock:
                        print(f"âŒ Lá»—i unexpected khi xá»­ lÃ½ trang {page_num}: {e}")
                    failed_pages += 1
        
        # Sáº¯p xáº¿p vÃ  ghÃ©p káº¿t quáº£ theo thá»© tá»± trang
        print(f"\nğŸ”— Äang ghÃ©p káº¿t quáº£ tá»« {len(page_results)} trang...")
        
        current_index = 1
        for page_num in sorted(page_results.keys()):
            result = page_results[page_num]
            if result['success'] and result['items']:
                # Update index Ä‘á»ƒ khÃ´ng trÃ¹ng láº·p
                for item in result['items']:
                    item['index'] = current_index
                    current_index += 1
                
                all_music_items.extend(result['items'])
                print(f"ğŸ“„ Trang {page_num}: ÄÃ£ thÃªm {len(result['items'])} tracks")
        
        print(f"\nğŸ“Š Tá»”NG Káº¾T CRAWLING:")
        print(f"âœ… ThÃ nh cÃ´ng: {successful_pages}/{total_pages} trang")
        print(f"âŒ Tháº¥t báº¡i: {failed_pages}/{total_pages} trang")
        print(f"ğŸ“Š Tá»· lá»‡ thÃ nh cÃ´ng: {(successful_pages/total_pages*100):.1f}%")
        print(f"ğŸ“„ Range: Trang {start_page}-{end_page}")
        print(f"ğŸµ Tá»•ng tracks: {len(all_music_items)}")
        print("=" * 70)
        
        self.music_list = all_music_items
        return all_music_items
    
    def _try_alternative_methods(self, url: str) -> List[Dict]:
        """
        Thá»­ cÃ¡c phÆ°Æ¡ng phÃ¡p thay tháº¿ khi gáº·p lá»—i 403 hoáº·c blocked
        """
        print("ğŸ”„ Äang thá»­ cÃ¡c phÆ°Æ¡ng phÃ¡p thay tháº¿...")
        
        # Method 1: Thá»­ vá»›i session má»›i vÃ  headers khÃ¡c
        try:
            print("ğŸ“‹ PhÆ°Æ¡ng phÃ¡p 1: Session má»›i + headers khÃ¡c...")
            new_session = requests.Session()
            new_session.headers.update({
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/119.0',
                'Accept': '*/*',
                'Accept-Language': 'en-US,en;q=0.5',
                'Referer': 'https://pixabay.com/',
                'Origin': 'https://pixabay.com'
            })
            
            time.sleep(3)
            response = new_session.get(url, timeout=30)
            if response.status_code == 200:
                print("âœ… ThÃ nh cÃ´ng vá»›i phÆ°Æ¡ng phÃ¡p 1!")
                return self._parse_response_content(response.content, url)
                
        except Exception as e:
            print(f"âŒ PhÆ°Æ¡ng phÃ¡p 1 tháº¥t báº¡i: {e}")
        
        # Method 2: Thá»­ URL Ä‘Æ¡n giáº£n hÆ¡n 
        try:
            print("ğŸ“‹ PhÆ°Æ¡ng phÃ¡p 2: URL Ä‘Æ¡n giáº£n...")
            simple_url = "https://pixabay.com/music/search/piano/"
            response = self.session.get(simple_url, timeout=30)
            if response.status_code == 200:
                print("âœ… ThÃ nh cÃ´ng vá»›i URL Ä‘Æ¡n giáº£n!")
                return self._parse_response_content(response.content, simple_url)
                
        except Exception as e:
            print(f"âŒ PhÆ°Æ¡ng phÃ¡p 2 tháº¥t báº¡i: {e}")
        
        # Method 3: Gá»£i Ã½ sá»­ dá»¥ng URL trá»±c tiáº¿p
        print("ğŸ“‹ PhÆ°Æ¡ng phÃ¡p 3: HÆ°á»›ng dáº«n láº¥y URL trá»±c tiáº¿p...")
        print("""
ğŸ’¡ Gá»¢I Ã: Pixabay cÃ³ thá»ƒ cáº§n truy cáº­p trá»±c tiáº¿p qua browser.
HÃ£y thá»­:
1. Má»Ÿ {url} trong browser
2. Má»Ÿ Developer Tools (F12)
3. TÃ¬m cÃ¡c file .mp3 trong Network tab
4. Copy URL trá»±c tiáº¿p cá»§a file MP3

Hoáº·c nháº­p URL khÃ¡c Ä‘á»ƒ thá»­:""".format(url=url))
        
        return self._create_demo_list()
    
    def _parse_response_content(self, content: bytes, url: str) -> List[Dict]:
        """
        Parse ná»™i dung response thÃ nh danh sÃ¡ch nháº¡c
        """
        soup = BeautifulSoup(content, 'html.parser')
        music_items = []
        
        # Debug: TÃ¬m hiá»ƒu cáº¥u trÃºc HTML thá»±c táº¿
        print("ğŸ” Äang phÃ¢n tÃ­ch cáº¥u trÃºc HTML...")
        
        # TÃ¬m cÃ¡c patterns cá»¥ thá»ƒ cá»§a Pixabay (dá»±a trÃªn HTML thá»±c)
        patterns_to_try = [
            ('div[class*="audioRow"]', 'Pixabay audioRow containers'),
            ('div[class*="Row"]', 'Pixabay Row containers'),
            ('div[class*="item"]', 'div cÃ³ class chá»©a "item"'),
            ('div[class*="media"]', 'div cÃ³ class chá»©a "media"'),
            ('div[class*="result"]', 'div cÃ³ class chá»©a "result"'),
            ('div[class*="track"]', 'div cÃ³ class chá»©a "track"'),
            ('div[class*="audio"]', 'div cÃ³ class chá»©a "audio"'),
            ('div[class*="music"]', 'div cÃ³ class chá»©a "music"'),
            ('article', 'article elements'),
            ('div[data-id]', 'div cÃ³ data-id'),
            ('.item', 'class item'),
            ('.media', 'class media'),
            ('.track', 'class track'),
            ('[data-track]', 'elements cÃ³ data-track'),
            ('[data-audio]', 'elements cÃ³ data-audio'),
        ]
        
        items = []
        for selector, description in patterns_to_try:
            try:
                found_items = soup.select(selector)
                if found_items:
                    print(f"âœ… TÃ¬m tháº¥y {len(found_items)} items vá»›i selector: {description}")
                    items = found_items
                    break
                else:
                    print(f"âŒ KhÃ´ng tÃ¬m tháº¥y vá»›i selector: {description}")
            except Exception as e:
                print(f"âš ï¸  Lá»—i vá»›i selector {description}: {e}")
        
        if not items:
            # Fallback: tÃ¬m táº¥t cáº£ divs vÃ  filter
            print("ğŸ”„ Thá»­ fallback method...")
            all_divs = soup.find_all('div')
            print(f"ğŸ“Š Tá»•ng sá»‘ div tags: {len(all_divs)}")
            
            # TÃ¬m divs cÃ³ thá»ƒ chá»©a thÃ´ng tin nháº¡c
            for div in all_divs[:50]:  # Chá»‰ check 50 divs Ä‘áº§u
                if any(keyword in str(div.get('class', [])).lower() for keyword in ['item', 'media', 'track', 'music', 'audio', 'result']):
                    items.append(div)
                elif any(attr.startswith('data-') for attr in div.attrs if 'id' in attr or 'track' in attr or 'audio' in attr):
                    items.append(div)
        
        print(f"ğŸ“‹ Cuá»‘i cÃ¹ng tÃ¬m tháº¥y {len(items)} items Ä‘á»ƒ parse")
        
        for idx, item in enumerate(items):
            try:
                print(f"\nğŸ” Äang parse item {idx + 1}...")
                
                # Debug: In ra thÃ´ng tin cÆ¡ báº£n cá»§a item
                item_classes = item.get('class', [])
                item_id = item.get('id', '')
                print(f"   Classes: {item_classes}")
                print(f"   ID: {item_id}")
                
                # TÃ¬m title theo cáº¥u trÃºc Pixabay cá»¥ thá»ƒ
                title = "Unknown Track"
                
                # Pixabay cÃ³ class title--xxxxx trong structure
                title_selectors = [
                    'a[class*="title"]',  # a.title--7N7Nr
                    '[class*="title"]',   # CÃ¡c element khÃ¡c cÃ³ title
                    'h1', 'h2', 'h3', 'h4', 'h5', 'h6',
                    '[title]', '[alt]', 
                    '.nameAndTitle a:first-child',  # Link Ä‘áº§u tiÃªn trong nameAndTitle
                    'a[href*="/music/"]',  # Links Ä‘áº¿n trang music
                    'span', 'div', 'p'
                ]
                
                for selector in title_selectors:
                    title_elem = item.select_one(selector)
                    if title_elem:
                        candidate_title = title_elem.get_text(strip=True) or title_elem.get('title', '') or title_elem.get('alt', '')
                        if candidate_title and len(candidate_title) > 2 and candidate_title != 'Unknown Track':
                            title = candidate_title
                            print(f"   âœ… TÃ¬m tháº¥y title vá»›i selector '{selector}': {title}")
                            break
                
                # TÃ¬m download link - Pixabay sá»­ dá»¥ng JavaScript cho download
                download_link = None
                
                # 1. TÃ¬m URL trang chi tiáº¿t (Ä‘á»ƒ cÃ³ thá»ƒ fetch sau)
                detail_link = None
                detail_links = item.find_all('a', href=True)
                for link in detail_links:
                    href = link.get('href', '')
                    if '/music/' in href and any(word in href for word in ['/', '-']):
                        detail_link = urljoin(url, href)
                        print(f"   âœ… TÃ¬m tháº¥y detail page: {detail_link}")
                        break
                
                # 2. TÃ¬m audio elements (Ã­t kháº£ nÄƒng cÃ³)
                audio_elem = item.find('audio')
                if audio_elem and audio_elem.get('src'):
                    download_link = urljoin(url, audio_elem['src'])
                    print(f"   âœ… TÃ¬m tháº¥y audio src: {download_link}")
                
                # 3. TÃ¬m data attributes cÃ³ thá»ƒ chá»©a track ID
                track_id = None
                if not download_link:
                    for attr, value in item.attrs.items():
                        if 'data' in attr.lower() and ('id' in attr.lower() or 'track' in attr.lower()):
                            track_id = str(value)
                            print(f"   âœ… TÃ¬m tháº¥y track ID: {track_id}")
                            break
                
                # 4. Extract ID tá»« detail link náº¿u cÃ³
                if not track_id and detail_link:
                    # Pixabay URLs thÆ°á»ng cÃ³ format: /music/title-123456/
                    id_match = re.search(r'-(\d+)/?$', detail_link)
                    if id_match:
                        track_id = id_match.group(1)
                        print(f"   âœ… Extract track ID tá»« URL: {track_id}")
                
                # 5. Æ¯u tiÃªn dÃ¹ng detail page Ä‘á»ƒ fetch URL thá»±c
                if detail_link:
                    download_link = detail_link
                    print(f"   ğŸ”— Sáº½ fetch URL thá»±c tá»« detail page: {detail_link}")
                elif track_id:
                    # Backup: thá»­ cÃ¡c format kháº£ dÄ©
                    possible_formats = [
                        f"https://cdn.pixabay.com/audio/2023/{track_id}.mp3",
                        f"https://cdn.pixabay.com/audio/2024/{track_id}.mp3", 
                        f"https://pixabay.com/get/{track_id}.mp3",
                        f"https://pixabay.com/music/download/{track_id}.mp3"
                    ]
                    download_link = possible_formats[0]
                    print(f"   ğŸ”— Táº¡o download link giáº£ Ä‘á»‹nh: {download_link}")
                
                # 6. TÃ¬m trong child elements náº¿u váº«n chÆ°a cÃ³
                if not download_link:
                    for child in item.find_all(recursive=True):
                        for attr, value in child.attrs.items():
                            if any(ext in str(value).lower() for ext in ['.mp3', '.wav', '.m4a']) and 'http' in str(value):
                                download_link = urljoin(url, str(value))
                                print(f"   âœ… TÃ¬m tháº¥y trong child: {download_link}")
                                break
                        if download_link:
                            break
                
                if download_link:
                    music_items.append({
                        'title': title,
                        'download_url': download_link,
                        'index': len(music_items) + 1
                    })
                    print(f"   âœ… ÄÃ£ thÃªm vÃ o danh sÃ¡ch: {title}")
                else:
                    print(f"   âŒ KhÃ´ng tÃ¬m tháº¥y download link cho item nÃ y")
                    
            except Exception as e:
                print(f"âš ï¸  Lá»—i khi parse item {idx}: {e}")
                continue
        
        # Náº¿u khÃ´ng tÃ¬m tháº¥y gÃ¬, thá»­ tÃ¬m trong JavaScript/JSON data
        if not music_items:
            print("\nğŸ” TÃ¬m kiáº¿m trong JavaScript/JSON data...")
            scripts = soup.find_all('script')
            for idx, script in enumerate(scripts[:10]):  # Chá»‰ check 10 scripts Ä‘áº§u
                if script.string:
                    script_content = script.string
                    
                    # TÃ¬m URLs MP3 trong JavaScript
                    if any(keyword in script_content.lower() for keyword in ['mp3', 'audio', 'music', 'track']):
                        print(f"   ğŸ“œ Script {idx + 1} cÃ³ thá»ƒ chá»©a thÃ´ng tin audio...")
                        
                        # Patterns Ä‘á»ƒ extract URLs
                        url_patterns = [
                            r'["\']([^"\']*\.mp3[^"\']*)["\']',
                            r'["\']([^"\']*\.wav[^"\']*)["\']',
                            r'["\']([^"\']*\.m4a[^"\']*)["\']',
                            r'["\']([^"\']*audio[^"\']*\.mp3)["\']',
                            r'download["\']:\s*["\']([^"\']*)["\']',
                            r'src["\']:\s*["\']([^"\']*\.mp3[^"\']*)["\']'
                        ]
                        
                        for pattern in url_patterns:
                            urls = re.findall(pattern, script_content, re.IGNORECASE)
                            for url_match in urls:
                                if url_match and len(url_match) > 10:  # Filter out short false matches
                                    full_url = urljoin(url, url_match)
                                    music_items.append({
                                        'title': f"JS Track {len(music_items) + 1}",
                                        'download_url': full_url,
                                        'index': len(music_items) + 1
                                    })
                                    print(f"   âœ… TÃ¬m tháº¥y URL trong JS: {url_match}")
                        
                        # TÃ¬m thÃ´ng tin JSON
                        json_patterns = [
                            r'\{[^}]*"title"[^}]*"url"[^}]*\}',
                            r'\{[^}]*"name"[^}]*"src"[^}]*\}',
                            r'\{[^}]*"audio"[^}]*\}'
                        ]
                        
                        for pattern in json_patterns:
                            matches = re.findall(pattern, script_content, re.IGNORECASE)
                            for match in matches:
                                try:
                                    # Thá»­ parse JSON-like structure
                                    if '"title"' in match and '"url"' in match:
                                        title_match = re.search(r'"title":\s*"([^"]*)"', match)
                                        url_match = re.search(r'"url":\s*"([^"]*)"', match)
                                        if title_match and url_match:
                                            music_items.append({
                                                'title': title_match.group(1),
                                                'download_url': urljoin(url, url_match.group(1)),
                                                'index': len(music_items) + 1
                                            })
                                            print(f"   âœ… TÃ¬m tháº¥y JSON track: {title_match.group(1)}")
                                except Exception as e:
                                    print(f"   âš ï¸  Lá»—i parse JSON: {e}")
        
        print(f"\nğŸ“Š Tá»•ng cá»™ng tÃ¬m tháº¥y {len(music_items)} tracks")
        return music_items
    
    def _create_demo_list(self) -> List[Dict]:
        """
        Táº¡o danh sÃ¡ch demo Ä‘á»ƒ test tool
        """
        print("ğŸµ Táº¡o danh sÃ¡ch demo Ä‘á»ƒ test...")
        return [
            {
                'title': 'Demo Piano Track 1',
                'download_url': 'https://pixabay.com/music/download/demo1.mp3',
                'index': 1
            },
            {
                'title': 'Demo Piano Track 2', 
                'download_url': 'https://pixabay.com/music/download/demo2.mp3',
                'index': 2
            },
            {
                'title': 'Demo Piano Track 3',
                'download_url': 'https://pixabay.com/music/download/demo3.mp3', 
                'index': 3
            }
        ]
    
    def display_music_list(self):
        """
        Hiá»ƒn thá»‹ danh sÃ¡ch nháº¡c vá»›i sá»‘ thá»© tá»±
        """
        if not self.music_list:
            print("ğŸ“­ KhÃ´ng cÃ³ nháº¡c nÃ o trong danh sÃ¡ch")
            return
            
        print("\n" + "="*80)
        print("ğŸµ DANH SÃCH NHáº C TÃŒM THáº¤Y")
        print("="*80)
        
        current_page = None
        for item in self.music_list:
            # Hiá»ƒn thá»‹ header cho trang má»›i
            if 'page' in item and item['page'] != current_page:
                current_page = item['page']
                if current_page > 1:
                    print(f"\nğŸ“„ --- TRANG {current_page} ---")
            
            page_info = f" (Trang {item['page']})" if 'page' in item else ""
            print(f"{item['index']:3d}. {item['title']}{page_info}")
            print(f"     URL: {item['download_url'][:60]}...")
            print()
    
    def _try_get_real_download_url(self, fake_url: str, title: str) -> str:
        """
        Thá»­ láº¥y URL download thá»±c tá»« Pixabay
        """
        try:
            print(f"   ğŸ” Thá»­ láº¥y URL thá»±c cho: {title}")
            
            # Náº¿u lÃ  detail page, thá»­ fetch vÃ  tÃ¬m download link
            if '/music/' in fake_url and not fake_url.endswith('.mp3'):
                print(f"   ğŸ“„ Fetching detail page: {fake_url}")
                
                # ThÃªm headers Ä‘á»ƒ giáº£ láº­p browser
                headers = {
                    'Referer': 'https://pixabay.com/',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'
                }
                
                response = self.session.get(fake_url, timeout=15, headers=headers)
                if response.status_code == 200:
                    soup = BeautifulSoup(response.content, 'html.parser')
                    
                    print(f"   ğŸ“Š Detail page size: {len(response.content):,} bytes")
                    
                    # TÃ¬m trong JavaScript data
                    scripts = soup.find_all('script')
                    for script in scripts:
                        if script.string:
                            script_content = script.string
                            
                            # TÃ¬m URLs MP3 trong JavaScript vá»›i patterns máº¡nh hÆ¡n
                            patterns = [
                                r'"download"[^"]*"([^"]*\.mp3[^"]*)"',
                                r'"url"[^"]*"([^"]*\.mp3[^"]*)"',
                                r'"src"[^"]*"([^"]*\.mp3[^"]*)"',
                                r'cdn\.pixabay\.com/audio/[^"\']*\.mp3',
                                r'https://[^"\']*\.mp3',
                                r'["\']([^"\']*cdn\.pixabay\.com[^"\']*\.mp3)["\']'
                            ]
                            
                            for pattern in patterns:
                                matches = re.findall(pattern, script_content, re.IGNORECASE)
                                for match in matches:
                                    if match and len(match) > 20 and '.mp3' in match:
                                        if not match.startswith('http'):
                                            match = 'https:' + match if match.startswith('//') else 'https://' + match
                                        print(f"   âœ… TÃ¬m tháº¥y URL trong JS: {match}")
                                        return match
                    
                    # TÃ¬m audio elements vÃ  download buttons
                    download_patterns = [
                        'audio[src]',
                        'source[src]',
                        'a[href*=".mp3"]',
                        '[data-url*=".mp3"]',
                        '[onclick*=".mp3"]'
                    ]
                    
                    for pattern in download_patterns:
                        elements = soup.select(pattern)
                        for elem in elements:
                            url_attrs = ['src', 'href', 'data-url', 'onclick']
                            for attr in url_attrs:
                                href = elem.get(attr, '')
                                if href and '.mp3' in href:
                                    if 'javascript:' not in href.lower():
                                        real_url = urljoin(fake_url, href)
                                        print(f"   âœ… TÃ¬m tháº¥y URL tá»« {pattern}: {real_url}")
                                        return real_url
                    
                    print(f"   âŒ KhÃ´ng tÃ¬m tháº¥y URL download trong detail page")
            
            # Náº¿u lÃ  URL giáº£ Ä‘á»‹nh, thá»­ test nÃ³
            elif fake_url.endswith('.mp3'):
                print(f"   ğŸ§ª Test URL giáº£ Ä‘á»‹nh: {fake_url}")
                try:
                    head_response = self.session.head(fake_url, timeout=8)
                    if head_response.status_code == 200:
                        content_type = head_response.headers.get('content-type', '')
                        if 'audio' in content_type.lower() or 'mpeg' in content_type.lower():
                            print(f"   âœ… URL giáº£ Ä‘á»‹nh hoáº¡t Ä‘á»™ng!")
                            return fake_url
                    print(f"   âŒ URL giáº£ Ä‘á»‹nh khÃ´ng hoáº¡t Ä‘á»™ng: {head_response.status_code}")
                except:
                    print(f"   âŒ KhÃ´ng thá»ƒ test URL giáº£ Ä‘á»‹nh")
                    
        except Exception as e:
            print(f"   âš ï¸  Lá»—i khi láº¥y URL thá»±c: {e}")
        
        # Fallback: return detail page Ä‘á»ƒ cÃ³ thá»ƒ thá»­ manual
        print(f"   ğŸ”„ Fallback: sá»­ dá»¥ng detail page")
        return fake_url

    def _get_next_file_index(self, download_folder: str) -> int:
        """
        Kiá»ƒm tra thÆ° má»¥c vÃ  tráº£ vá» sá»‘ thá»© tá»± tiáº¿p theo Ä‘á»ƒ trÃ¡nh ghi Ä‘Ã¨ file cÅ©
        """
        if not os.path.exists(download_folder):
            return 1
        
        max_index = 0
        try:
            files = os.listdir(download_folder)
            for filename in files:
                if filename.endswith('.mp3'):
                    # TÃ¬m pattern 001_, 002_, etc.
                    match = re.match(r'^(\d{3})_', filename)
                    if match:
                        index = int(match.group(1))
                        max_index = max(max_index, index)
            
            print(f"ğŸ“‚ TÃ¬m tháº¥y {len([f for f in files if f.endswith('.mp3')])} file MP3 trong thÆ° má»¥c")
            if max_index > 0:
                print(f"ğŸ“Š Sá»‘ thá»© tá»± cao nháº¥t hiá»‡n táº¡i: {max_index}")
                print(f"ğŸ†• File má»›i sáº½ báº¯t Ä‘áº§u tá»«: {max_index + 1}")
            
        except Exception as e:
            print(f"âš ï¸  Lá»—i khi scan thÆ° má»¥c: {e}")
        
        return max_index + 1

    def _download_single_file(self, item: Dict, download_folder: str, file_number: int) -> Dict:
        """
        Download má»™t file nháº¡c Ä‘Æ¡n láº» - dÃ¹ng cho threading
        Returns: Dict vá»›i thÃ´ng tin káº¿t quáº£ download
        """
        result = {
            'item': item,
            'success': False,
            'error': None,
            'filename': None,
            'file_size': 0
        }
        
        try:
            # LÃ m sáº¡ch tÃªn file
            safe_title = re.sub(r'[<>:"/\\|?*]', '_', item['title'])
            filename = f"{file_number:03d}_{safe_title}.mp3"
            filepath = os.path.join(download_folder, filename)
            result['filename'] = filename
            
            with self.print_lock:
                print(f"â¬‡ï¸  [{threading.current_thread().name}] Äang download {item['index']}: {item['title']}")
            
            # Thá»­ láº¥y URL thá»±c trÆ°á»›c khi download
            real_url = self._try_get_real_download_url(item['download_url'], item['title'])
            
            # Táº¡o session riÃªng cho thread nÃ y Ä‘á»ƒ trÃ¡nh xung Ä‘á»™t
            thread_session = requests.Session()
            thread_session.headers.update(self.session.headers)
            
            # Download file
            with self.print_lock:
                print(f"   ğŸŒ [{threading.current_thread().name}] Downloading tá»«: {real_url}")
            
            response = thread_session.get(real_url, stream=True, timeout=30)
            response.raise_for_status()
            
            # Kiá»ƒm tra content type
            content_type = response.headers.get('content-type', '')
            if 'audio' not in content_type.lower() and 'mpeg' not in content_type.lower():
                with self.print_lock:
                    print(f"âš ï¸  [{threading.current_thread().name}] Cáº£nh bÃ¡o: File cÃ³ thá»ƒ khÃ´ng pháº£i MP3 (Content-Type: {content_type})")
            
            # LÆ°u file
            with open(filepath, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
            
            file_size = os.path.getsize(filepath)
            result['file_size'] = file_size
            
            if file_size > 1024 * 1024:  # > 1MB
                size_str = f"{file_size / (1024*1024):.1f}MB"
            else:
                size_str = f"{file_size:,} bytes"
            
            with self.print_lock:
                print(f"âœ… [{threading.current_thread().name}] HoÃ n thÃ nh: {filename} ({size_str})")
            
            result['success'] = True
            
        except Exception as e:
            result['error'] = str(e)
            with self.print_lock:
                print(f"âŒ [{threading.current_thread().name}] Lá»—i download {item['title']}: {e}")
        
        return result

    def download_music_range(self, start_idx: int, end_idx: int, download_folder: str = "downloads", max_workers: int = 4):
        """
        Download nháº¡c theo range tá»« start_idx Ä‘áº¿n end_idx sá»­ dá»¥ng multi-threading
        max_workers: Sá»‘ thread tá»‘i Ä‘a (máº·c Ä‘á»‹nh 4)
        """
        if not self.music_list:
            print("âŒ ChÆ°a cÃ³ danh sÃ¡ch nháº¡c. Vui lÃ²ng parse trang trÆ°á»›c.")
            return
        
        # Validate range
        if start_idx < 1 or end_idx > len(self.music_list) or start_idx > end_idx:
            print(f"âŒ Range khÃ´ng há»£p lá»‡. Vui lÃ²ng chá»n tá»« 1 Ä‘áº¿n {len(self.music_list)}")
            return
        
        # Táº¡o folder download
        os.makedirs(download_folder, exist_ok=True)
        
        # Kiá»ƒm tra thÆ° má»¥c vÃ  láº¥y sá»‘ thá»© tá»± tiáº¿p theo
        next_file_index = self._get_next_file_index(download_folder)
        
        # TÃ­nh toÃ¡n sá»‘ file cáº§n download
        total_files = end_idx - start_idx + 1
        
        print(f"\nğŸš€ Báº¯t Ä‘áº§u download tá»« {start_idx} Ä‘áº¿n {end_idx} ({total_files} files)")
        print(f"ğŸ“ ThÆ° má»¥c lÆ°u: {download_folder}")
        print(f"ğŸ§µ Sá»­ dá»¥ng {max_workers} threads song song")
        if next_file_index > 1:
            print(f"ğŸ”¢ Sá»‘ thá»© tá»± file sáº½ báº¯t Ä‘áº§u tá»«: {next_file_index}")
        print("-" * 60)
        
        # Chuáº©n bá»‹ danh sÃ¡ch download jobs
        download_jobs = []
        for i in range(start_idx - 1, end_idx):
            if i >= len(self.music_list):
                break
            
            item = self.music_list[i]
            file_number = next_file_index + (i - (start_idx - 1))
            download_jobs.append((item, file_number))
        
        print(f"ğŸ“‹ ÄÃ£ chuáº©n bá»‹ {len(download_jobs)} jobs download...")
        
        # Khá»Ÿi táº¡o counters
        success_count = 0
        failed_count = 0
        completed_count = 0
        
        # Sá»­ dá»¥ng ThreadPoolExecutor Ä‘á»ƒ download song song
        with ThreadPoolExecutor(max_workers=max_workers, thread_name_prefix="Downloader") as executor:
            # Submit táº¥t cáº£ jobs
            future_to_job = {
                executor.submit(self._download_single_file, item, download_folder, file_number): (item, file_number) 
                for item, file_number in download_jobs
            }
            
            print(f"ğŸ¯ ÄÃ£ submit {len(future_to_job)} download tasks...")
            print("â³ Äang download... (cÃ³ thá»ƒ máº¥t vÃ i phÃºt)")
            print("-" * 60)
            
            # Xá»­ lÃ½ káº¿t quáº£ khi cÃ¡c thread hoÃ n thÃ nh
            for future in as_completed(future_to_job):
                item, file_number = future_to_job[future]
                completed_count += 1
                
                try:
                    result = future.result()
                    
                    with self.progress_lock:
                        if result['success']:
                            success_count += 1
                        else:
                            failed_count += 1
                        
                        # Hiá»ƒn thá»‹ tiáº¿n Ä‘á»™
                        progress = (completed_count / len(download_jobs)) * 100
                        print(f"\nğŸ“Š Tiáº¿n Ä‘á»™: {completed_count}/{len(download_jobs)} ({progress:.1f}%)")
                        print(f"âœ… ThÃ nh cÃ´ng: {success_count} | âŒ Tháº¥t báº¡i: {failed_count}")
                        
                except Exception as e:
                    with self.print_lock:
                        print(f"âŒ Lá»—i unexpected khi xá»­ lÃ½ {item['title']}: {e}")
                    failed_count += 1
        
        print(f"\n" + "="*60)
        print(f"ğŸ HOÃ€N THÃ€NH DOWNLOAD")
        print(f"ğŸ“Š Káº¾T QUáº¢ CUá»I CÃ™NG:")
        print(f"   âœ… ThÃ nh cÃ´ng: {success_count}/{len(download_jobs)}")
        print(f"   âŒ Tháº¥t báº¡i: {failed_count}/{len(download_jobs)}")
        print(f"   ğŸ“Š Tá»· lá»‡ thÃ nh cÃ´ng: {(success_count/len(download_jobs)*100):.1f}%")
        print(f"ğŸ“ ThÆ° má»¥c: {os.path.abspath(download_folder)}")
        print("="*60)

def handle_direct_urls():
    """
    Xá»­ lÃ½ download tá»« URL trá»±c tiáº¿p
    """
    print("\nğŸ“¥ DOWNLOAD TRá»°C TIáº¾P Tá»ª URL")
    print("=" * 50)
    print("Nháº­p cÃ¡c URL file MP3, má»—i URL má»™t dÃ²ng.")
    print("Nháº­p 'done' Ä‘á»ƒ hoÃ n thÃ nh:")
    
    urls = []
    while True:
        url = input(f"URL {len(urls) + 1}: ").strip()
        if url.lower() == 'done':
            break
        if url:
            urls.append(url)
    
    if not urls:
        print("âŒ KhÃ´ng cÃ³ URL nÃ o Ä‘Æ°á»£c nháº­p.")
        return
    
    # Táº¡o downloader vÃ  fake music list
    downloader = PixabayMusicDownloader()
    downloader.music_list = [
        {
            'title': f'Direct Download {i+1}',
            'download_url': url,
            'index': i + 1
        } for i, url in enumerate(urls)
    ]
    
    # Hiá»ƒn thá»‹ vÃ  download
    downloader.display_music_list()
    
    try:
        print(f"\nğŸ“ Download táº¥t cáº£ {len(urls)} file?")
        folder_input = input("ThÆ° má»¥c lÆ°u (Enter = 'downloads'): ").strip()
        folder = folder_input if folder_input else "downloads"
        
        confirm = input(f"\nXÃ¡c nháº­n download {len(urls)} file vÃ o '{folder}'? (y/N): ").strip().lower()
        
        if confirm in ['y', 'yes']:
            downloader.download_music_range(1, len(urls), folder)
        else:
            print("âŒ ÄÃ£ há»§y download.")
            
    except KeyboardInterrupt:
        print("\n\nâŒ ÄÃ£ há»§y bá»Ÿi ngÆ°á»i dÃ¹ng.")
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")

def main():
    """
    HÃ m main Ä‘á»ƒ cháº¡y tool
    """
    downloader = PixabayMusicDownloader()
    
    print("ğŸµ PIXABAY MUSIC DOWNLOADER")
    print("=" * 50)
    
    # URL máº·c Ä‘á»‹nh tá»« user
    default_url = "https://pixabay.com/vi/music/search/nh%e1%ba%a1c%20kh%c3%b4ng%20b%e1%ba%a3n%20quy%e1%bb%81n/?genre=piano+solo"
    
    # Nháº­p URL (hoáº·c dÃ¹ng máº·c Ä‘á»‹nh)
    url_input = input(f"Nháº­p URL Pixabay (Enter Ä‘á»ƒ dÃ¹ng máº·c Ä‘á»‹nh):\n{default_url}\n> ").strip()
    url = url_input if url_input else default_url
    
    # Há»i vá» pagination
    print("\nğŸ”„ TÃ™Y CHá»ŒN CRAWLING:")
    print("1. Chá»‰ crawl trang Ä‘áº§u tiÃªn (nhanh)")
    print("2. Crawl nhiá»u trang (cháº­m hÆ¡n nhÆ°ng cÃ³ nhiá»u nháº¡c hÆ¡n)")
    
    crawl_choice = input("Chá»n (1/2, Enter = 1): ").strip()
    
    if crawl_choice == '2':
        try:
            start_page = int(input("Tá»« trang (Enter = 1): ").strip() or "1")
            end_page = int(input("Äáº¿n trang (Enter = 3): ").strip() or "3")
            
            # Validate input
            start_page = max(start_page, 1)  # Tá»‘i thiá»ƒu trang 1
            end_page = min(max(end_page, start_page), 100)  # Tá»‘i Ä‘a trang 100
            
            if start_page > end_page:
                start_page, end_page = end_page, start_page  # Swap náº¿u ngÆ°á»£c
            
            total_pages = end_page - start_page + 1
            
            # TÃ¹y chá»n threads cho parsing
            if total_pages > 1:
                parse_threads_input = input(f"Sá»‘ threads cho parsing (Enter = 3, tá»‘i Ä‘a 5): ").strip()
                try:
                    parse_threads = int(parse_threads_input) if parse_threads_input else 3
                    parse_threads = min(max(parse_threads, 1), 5)  # Giá»›i háº¡n tá»« 1-5
                except ValueError:
                    parse_threads = 3
                    print("âŒ Sá»‘ khÃ´ng há»£p lá»‡, dÃ¹ng máº·c Ä‘á»‹nh 3 threads")
                
                print(f"ğŸš€ Sáº½ crawl tá»« trang {start_page} Ä‘áº¿n trang {end_page} ({total_pages} trang) vá»›i {parse_threads} threads...")
                music_list = downloader.parse_multiple_pages(url, start_page, end_page, parse_threads)
            else:
                print(f"ğŸš€ Sáº½ crawl tá»« trang {start_page} Ä‘áº¿n trang {end_page} ({total_pages} trang)...")
                music_list = downloader.parse_multiple_pages(url, start_page, end_page, 1)
        except ValueError:
            print("âŒ Sá»‘ khÃ´ng há»£p lá»‡, dÃ¹ng máº·c Ä‘á»‹nh trang 1-3")
            music_list = downloader.parse_multiple_pages(url, 1, 3, 3)
    else:
        print("ğŸš€ Crawl trang Ä‘áº§u tiÃªn...")
        music_list = downloader.parse_pixabay_page(url)
    
    if not music_list:
        print("âŒ KhÃ´ng thá»ƒ láº¥y danh sÃ¡ch nháº¡c tá»« trang nÃ y.")
        
        # Cho phÃ©p ngÆ°á»i dÃ¹ng thá»­ láº¡i vá»›i URL khÃ¡c
        while True:
            choice = input("""
ğŸ”„ Báº¡n muá»‘n:
1. Thá»­ láº¡i vá»›i URL khÃ¡c
2. Nháº­p trá»±c tiáº¿p URL file MP3
3. ThoÃ¡t
Chá»n (1/2/3): """).strip()
            
            if choice == '1':
                new_url = input("Nháº­p URL má»›i: ").strip()
                if new_url:
                    music_list = downloader.parse_pixabay_page(new_url)
                    if music_list:
                        break
            elif choice == '2':
                return handle_direct_urls()
            elif choice == '3':
                print("ğŸ‘‹ Táº¡m biá»‡t!")
                return
            else:
                print("âŒ Vui lÃ²ng chá»n 1, 2 hoáº·c 3.")
        
        if not music_list:
            return
    
    # Hiá»ƒn thá»‹ danh sÃ¡ch
    downloader.display_music_list()
    
    # Nháº­p range Ä‘á»ƒ download
    try:
        print(f"\nğŸ“ Nháº­p range Ä‘á»ƒ download (1-{len(music_list)}):")
        start = int(input("Tá»« sá»‘: ").strip())
        end = int(input("Äáº¿n sá»‘: ").strip())
        
        # Nháº­p thÆ° má»¥c lÆ°u (optional)
        folder_input = input("ThÆ° má»¥c lÆ°u (Enter = 'downloads'): ").strip()
        folder = folder_input if folder_input else "downloads"
        
        # TÃ¹y chá»n sá»‘ threads
        print(f"\nâš™ï¸  TÃ™Y CHá»ŒN THREADING:")
        threads_input = input("Sá»‘ threads download (Enter = 4, tá»‘i Ä‘a 8): ").strip()
        try:
            max_threads = int(threads_input) if threads_input else 4
            max_threads = min(max(max_threads, 1), 8)  # Giá»›i háº¡n tá»« 1-8
        except ValueError:
            max_threads = 4
            print("âŒ Sá»‘ khÃ´ng há»£p lá»‡, dÃ¹ng máº·c Ä‘á»‹nh 4 threads")
        
        # XÃ¡c nháº­n
        print(f"\nğŸ” Sáº¼ DOWNLOAD:")
        print(f"   - Tá»« bÃ i {start} Ä‘áº¿n bÃ i {end}")
        print(f"   - Tá»•ng cá»™ng: {end - start + 1} bÃ i")
        print(f"   - ThÆ° má»¥c: {folder}")
        print(f"   - Threads: {max_threads}")
        
        confirm = input("\nXÃ¡c nháº­n download? (y/N): ").strip().lower()
        
        if confirm in ['y', 'yes']:
            downloader.download_music_range(start, end, folder, max_threads)
        else:
            print("âŒ ÄÃ£ há»§y download.")
            
    except KeyboardInterrupt:
        print("\n\nâŒ ÄÃ£ há»§y bá»Ÿi ngÆ°á»i dÃ¹ng.")
    except ValueError:
        print("âŒ Vui lÃ²ng nháº­p sá»‘ há»£p lá»‡.")
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")

if __name__ == "__main__":
    main()
